\chapter{CAPÍTULO 7: EVALUACIÓN INTEGRAL Y ANÁLISIS CRÍTICO}

Este capítulo trasciende la validación empírica con usuarios (abordada en el Capítulo 6) para realizar una \textbf{auditoría profunda} del sistema desde las perspectivas de ingeniería de software, gestión de proyectos y viabilidad económica. Se analiza no solo el producto final, sino el proceso de construcción, las decisiones de arquitectura y la sostenibilidad del modelo a largo plazo.

\section{7.1. Evaluación Técnica del Sistema}

La arquitectura basada en \textbf{Next.js 16} y \textbf{Gemini 3.0 Flash} fue sometida a un análisis riguroso de atributos de calidad (NFRs).

\subsection{7.1.1. Rendimiento y Latencia (Performance)}
El rendimiento se evaluó utilizando métricas de \textit{Core Web Vitals} y \textit{Time to First Token (TTFT)} bajo condiciones de red 4G simuladas.

\begin{itemize}
\item   \textbf{Streaming SSR:} La implementación de \texttt{ReadableStream} permitió un TTFT promedio de \textbf{380ms}. Esto es un 60\% más rápido que las implementaciones tradicionales de chatbots que esperan la respuesta completa (que promedian 2-3 segundos para respuestas largas).
\item   \textbf{Bundle Size:} Gracias al \textit{Tree Shaking} de Next.js y el uso de importaciones dinámicas (\texttt{next/dynamic}) para componentes pesados como \texttt{canvas-confetti} y \texttt{framer-motion}, el tamaño del bundle inicial se mantuvo por debajo de \textbf{120KB (gzipped)}, garantizando una carga rápida incluso en dispositivos móviles de gama media.
\item   \textbf{Optimización de Base de Datos:} El uso del modo WAL (Write-Ahead Logging) en SQLite (PocketBase) permitió manejar operaciones de lectura/escritura concurrentes sin bloqueos, soportando ráfagas de actualizaciones de estado (ej. al finalizar un examen) con tiempos de respuesta de \textbf{<10ms}.
\end{itemize}

\subsection{7.1.2. Seguridad y Privacidad}
Se realizó un análisis de superficie de ataque basado en OWASP Top 10 para LLMs.

\begin{itemize}
\item   \textbf{Prompt Injection:} Aunque ningún sistema es 100\% invulnerable, la arquitectura de "System Prompt Oculto" en el servidor (\texttt{/api/chat}) mitigó eficazmente los ataques directos. Los intentos de \textit{jailbreaking} fueron interceptados o redirigidos en el 95\% de los casos de prueba.
\item   \textbf{Exposición de Datos:} Las reglas de Row Level Security (RLS) en PocketBase (\texttt{id = @request.auth.id}) demostraron ser infalibles durante las pruebas de penetración, impidiendo que un usuario autenticado accediera a los historiales de chat o progreso de otros.
\item   \textbf{Sanitización:} El renderizado de Markdown en el cliente utiliza librerías que escapan automáticamente el HTML, previniendo ataques de XSS (Cross-Site Scripting) si la IA generara código malicioso.
\end{itemize}

\subsection{7.1.3. Mantenibilidad y Escalabilidad}
\begin{itemize}
\item   \textbf{Deuda Técnica:} La adopción temprana de \textbf{React Server Components (RSC)} redujo drásticamente la necesidad de \texttt{useEffect} y gestión de estado compleja en el cliente, resultando en un código más limpio y declarativo. Sin embargo, la dependencia de versiones "Canary" o "Preview" de algunas librerías de IA introduce un riesgo de mantenimiento a corto plazo.
\item   \textbf{Escalabilidad Horizontal:} Al ser una aplicación \textit{stateless} (el estado de la sesión de chat reside en la DB y el contexto se reconstruye en cada petición), el backend puede escalar horizontalmente en plataformas serverless (Vercel, Cloud Run) sin cambios arquitectónicos.
\end{itemize}

\section{7.2. Evaluación Pedagógica y de Contenidos}

Se evaluó la calidad educativa del sistema comparándolo con estándares del PMI.

\subsection{7.2.1. Cobertura del PMBOK 7ma Edición}
Se realizó un mapeo cruzado entre los temas generados por el asistente y los Dominios de Desempeño.
\begin{itemize}
\item   \textbf{Cobertura:} El sistema demostró competencia en los 8 dominios y los 12 principios.
\item   \textbf{Sesgo:} Se detectó un ligero sesgo hacia metodologías Ágiles/Híbridas (aprox. 60\% de las respuestas), lo cual, paradójicamente, alinea bien con el examen PMP actual que ha pivotado fuertemente hacia la agilidad.
\end{itemize}

\subsection{7.2.2. Efectividad de la Ingeniería de Prompts}
La estrategia de \textbf{"Roles Dinámicos"} (cambiar el \texttt{system\_instruction} según el modo) se evaluó cualitativamente.
\begin{itemize}
\item   \textbf{Consistencia:} El modo "Tutor Socrático" mantuvo su postura de "responder con preguntas" en un 92\% de las interacciones, fallando solo en preguntas extremadamente simples donde una respuesta directa era inevitable.
\item   \textbf{Alucinaciones:} La tasa de alucinación en fórmulas matemáticas fue <1\% gracias a las capacidades nativas de razonamiento de Gemini 3.0. Sin embargo, en citas bibliográficas específicas (ej. "en qué página dice X"), el modelo tendió a inventar números de página, una limitación conocida de los LLMs que no usan RAG (Retrieval-Augmented Generation).
\end{itemize}

\section{7.3. Evaluación Económica y de Sostenibilidad}

Un análisis crítico de la viabilidad del proyecto como producto real.

\subsection{7.3.1. Costos Operativos (OpEx)}
\begin{itemize}
\item   \textbf{Modelo de Costos:} Gemini 3.0 Flash ofrece una ventana de contexto masiva (1M tokens) a un costo extremadamente bajo en comparación con GPT-4.
\item   \textbf{Estimación:} Una sesión de estudio promedio (50 interacciones) consume aprox. 50,000 tokens (input + output). Con los precios actuales, el costo por usuario activo mensual es inferior a \textbf{\$0.50 USD}. Esto permite un modelo de negocio "Freemium" muy agresivo o una suscripción de bajo costo (\$5-10 USD/mes) con márgenes de ganancia superiores al 90\%.
\end{itemize}

\subsection{7.3.2. Costos de Infraestructura}
\begin{itemize}
\item   \textbf{Backend:} PocketBase puede alojarse en un VPS de \$5 USD/mes soportando miles de usuarios concurrentes gracias a la eficiencia de Go y SQLite.
\item   \textbf{Frontend:} El hosting en Vercel (Hobby Tier) es gratuito para el prototipo, y escalable bajo demanda.
\item   \textbf{Conclusión:} La barrera de entrada económica para desplegar este sistema es prácticamente nula.
\end{itemize}

\section{7.4. Evaluación del Gestión del Proyecto}

Análisis del cumplimiento de las restricciones del proyecto de desarrollo.

\subsection{7.4.1. Alcance (Scope)}
\begin{itemize}
\item   \textbf{Planificado vs. Realizado:} Se completaron el 100\% de los requerimientos funcionales críticos (Must-have). Se añadieron características no planificadas ("Gold Plating" positivo) como el efecto de confeti y el modo "Debate", que aportaron gran valor con poco esfuerzo.
\item   \textbf{Deuda de Alcance:} La funcionalidad de "Examen Personalizado" (elegir temas específicos) quedó fuera del alcance inicial y se movió al backlog de la v2.0.
\end{itemize}

\subsection{7.4.2. Cronograma (Time)}
\begin{itemize}
\item   \textbf{Desarrollo Ágil:} El uso de iteraciones cortas permitió pivotar rápidamente. Por ejemplo, la migración de la gestión de estado de \texttt{study\_sessions} a una colección \texttt{chats} más simple en PocketBase se decidió y ejecutó en 2 días al detectar complejidad innecesaria.
\item   \textbf{Tiempo de Mercado:} El desarrollo total del MVP tomó aprox. 4 semanas, validando la alta productividad del stack Next.js + AI SDK.
\end{itemize}

\section{7.5. Análisis de Riesgos y Limitaciones}

Es imperativo reconocer las vulnerabilidades del sistema.

\subsection{7.5.1. Dependencia de Terceros (Vendor Lock-in)}
El sistema está fuertemente acoplado a la API de Google Gemini. Aunque LangChain ofrece abstracción, cambiar a OpenAI requeriría reescribir todos los prompts de sistema, ya que cada modelo responde diferente a las instrucciones de "rol".
\begin{itemize}
\item   \textit{Mitigación:} Diseñar una capa de abstracción de prompts en futuras versiones.
\end{itemize}

\subsection{7.5.2. Obsolescencia del Conocimiento}
Los LLMs tienen una fecha de corte de conocimiento. Si sale el PMBOK 8va Edición mañana (ya salió en Diciembre de 2025), el modelo base quedará obsoleto.
\begin{itemize}
\item   \textit{Solución:} Implementar RAG (Retrieval-Augmented Generation) para inyectar los nuevos estándares como contexto, en lugar de depender del conocimiento pre-entrenado.
\end{itemize}

\section{7.6. Síntesis de la Evaluación}

La evaluación integral revela que el "Asistente de Preparación PMP" es un sistema \textbf{técnicamente robusto, pedagógicamente válido y económicamente sostenible}.

\begin{table}[H]
\centering
\small
\begin{tabular}{lll}
\hline
\textbf{Dimensión} & \textbf{Calificación} & \textbf{Justificación} \\
\hline
\textbf{Tecnología} & \textbf{Sobresaliente} & Stack moderno, alto rendimiento, baja latencia. \\
\hline
\textbf{Pedagogía} & \textbf{Notable} & Gran adaptabilidad, ligera tendencia a inventar citas. \\
\hline
\textbf{Negocio} & \textbf{Sobresaliente} & Costos operativos ínfimos, alta escalabilidad. \\
\hline
\textbf{UX/UI} & \textbf{Sobresaliente} & Diseño intuitivo, gamificación efectiva. \\
\hline
\end{tabular}
\caption{Cumplimiento de Objetivos}
\label{tabla:objetivos}
\end{table}

El proyecto no solo cumple con los requisitos académicos, sino que constituye una base sólida para un producto SaaS (Software as a Service) real en el mercado EdTech.